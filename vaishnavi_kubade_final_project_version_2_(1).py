# -*- coding: utf-8 -*-
"""Vaishnavi Kubade_Final Project_version-2 (1).ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1JF-cmjkQc4bS4ivS4rlJylV1FeDbB2Xv

## Importing the Libraries
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

"""## Loading the Dataset"""

data = pd.read_excel('E Commerce Dataset.xlsx', sheet_name = 'E Comm')

data.head(30)

"""## EDA (Exploratoy Data Analysis)"""

data.shape

data.columns

data.info()

data.describe()

print(data['HourSpendOnApp'].mode())

"""### Renaming by Replacing"""

data['PreferredPaymentMode'] = data['PreferredPaymentMode'].replace('COD', 'Cash on Delivery')
data['PreferredPaymentMode'] = data['PreferredPaymentMode'].replace('CC', 'Credit Card')
data['PreferedOrderCat'] = data['PreferedOrderCat'].replace('Mobile', 'Mobile Phone')

"""#### Dealing with missing data"""

print(data.isnull().sum())

data.drop('CustomerID', axis=1, inplace=True)

#Dealing with missing data

updated_data = data

#replacing with mean
updated_data['Tenure'] = updated_data['Tenure'].fillna(updated_data['Tenure'].mean())
updated_data['WarehouseToHome'] = updated_data['WarehouseToHome'].fillna(updated_data['WarehouseToHome'].mean())
updated_data['HourSpendOnApp'] = updated_data['HourSpendOnApp'].fillna(updated_data['HourSpendOnApp'].mean())
updated_data['OrderAmountHikeFromlastYear'] = updated_data['OrderAmountHikeFromlastYear'].fillna(updated_data['OrderAmountHikeFromlastYear'].mean())
updated_data['CouponUsed'] = updated_data['CouponUsed'].fillna(updated_data['CouponUsed'].mean())

#replacing with median
updated_data['DaySinceLastOrder'] = updated_data['DaySinceLastOrder'].fillna(updated_data['DaySinceLastOrder'].median())

#deleting record
updated_data.dropna(subset = ['OrderCount'], inplace = True)
print(updated_data.isnull().sum())
print('Shape',updated_data.shape)

"""## Separate Independant and Dependant Variable"""

X = data.iloc[:, updated_data.columns != 'Churn']
X

y = data.iloc[:, :1]
y

"""#### Dummy Variables"""

#Creating Dummy variable and dropping 1 column (variable) from each categorical column

dummy_X = pd.get_dummies(X, drop_first = True)
dummy_X

dummy_X.columns

"""## Testing the Assumptions of Linear Regression Model
1. Linearity
2. Homoscedasticity
3. Lack of Multicollinearity
4. No auto-correlations of residuals
5. Residuals must be normally distributed
"""

#LINEARITY
data.columns

# No linearity found, it is a logistic regression - classification problem

sns.pairplot(data, x_vars = ['Tenure', 'PreferredLoginDevice', 'CityTier','WarehouseToHome'], y_vars = y.columns)

sns.pairplot(data, x_vars = ['Gender','HourSpendOnApp','NumberOfDeviceRegistered'], y_vars = y.columns)

#Lack of Multicollinearity
corr_X1 = dummy_X.corr().round(2)
corr_X1.head()

# Correlation Matrix and Heatmap
matrix_corr = dummy_X.select_dtypes(include=['int64', 'float64']).corr()
matrix_corr
plt.figure(figsize=(12, 10))

# Creates a heatmap from the correlation matrix
sns.heatmap(matrix_corr, annot=True, cmap='coolwarm', fmt=".2f")
plt.title('Correlation Matrix')
plt.show()

"""## Separate Training and Test Data"""

from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(dummy_X, y, test_size = 0.2, random_state = 0)

X_train.shape

X_test.shape

y_train.head()

y_train.Churn.value_counts()

"""## Feature Scaling"""

from sklearn.preprocessing import StandardScaler

stdS = StandardScaler()

X_train_scaled = stdS.fit_transform(X_train)

pd.DataFrame(X_train_scaled).head()

X_test_scaled = stdS.transform(X_test)

pd.DataFrame(X_test_scaled).head()

"""### OverSampling"""

from imblearn.over_sampling import SMOTE

x_resample, y_resample = SMOTE().fit_resample(X_train_scaled, y_train)

y_resample.Churn.value_counts()

"""## Logistic Regression"""

from sklearn.linear_model import LogisticRegression

logClassifier = LogisticRegression()

logClassifier.fit(x_resample, y_resample)

print("Accuracy on Train data:", logClassifier.score(x_resample, y_resample)*100)

print("Accuracy on Test data:", logClassifier.score(X_test_scaled, y_test)*100)

y_pred = logClassifier.predict(X_test_scaled)

y_pred

y_pred_prob = logClassifier.predict_proba(X_test_scaled)

y_pred_prob

y_pred_prob=pd.DataFrame(y_pred_prob)

y_pred_prob

"""#### Evaluating Logistic Regression"""

from sklearn.metrics import confusion_matrix, classification_report, roc_curve, roc_auc_score

confusion_matrix(y_test, y_pred)

print(classification_report(y_test, y_pred))

from sklearn import metrics
y_pred_proba = y_pred_prob.iloc[:,1]
fpr, tpr, _ = metrics.roc_curve(y_test,  y_pred_proba)
auc_log = metrics.auc(fpr, tpr)
print('AUC: ', auc_log)

plt.plot(fpr,tpr)
plt.ylabel('True Positive Rate')
plt.xlabel('False Positive Rate')
plt.show()

"""## KNN"""

from sklearn.neighbors import KNeighborsClassifier

k_value = []
error_value = []

for k in range(1,15):
    knn_classifier = KNeighborsClassifier(n_neighbors = k, metric = 'minkowski', p = 2)
    knn_classifier.fit(x_resample, y_resample)
    error = 1-knn_classifier.score(X_test_scaled, y_test)
    k_value.append(k)
    error_value.append(error)

plt.plot(k_value, error_value, marker = 'o')
plt.title('KNN Performance vs. K')
plt.xlabel('No. of Neighbors (K)')
plt.ylabel('Error')
plt.xticks(k_value)
plt.grid(True)
plt.show()

k_classifier = KNeighborsClassifier(n_neighbors = 1, metric = 'minkowski', p = 2)
k_classifier.fit(x_resample, y_resample)

y_pred_knn = knn_classifier.predict(X_test_scaled)

y_pred_knn

y_pred_prob_knn = knn_classifier.predict_proba(X_test_scaled)
y_pred_prob_knn = pd.DataFrame(y_pred_prob_knn)
y_pred_prob_knn

print('Accuracy of KNN on Training data : ', knn_classifier.score(x_resample, y_resample)*100)

print('Accuracy of KNN on Test data: ', knn_classifier.score(X_test_scaled, y_test)*100)

confusion_matrix(y_test, y_pred_knn)

print(classification_report(y_test, y_pred_knn))

y_pred_proba = y_pred_prob_knn.iloc[:,1]
fpr, tpr, _ = metrics.roc_curve(y_test,  y_pred_proba)
auc_knn = metrics.auc(fpr, tpr)
print('AUC: ',auc_knn)
plt.plot(fpr,tpr)
plt.ylabel('True Positive Rate')
plt.xlabel('False Positive Rate')
plt.title('ROC Curve for KNN')
plt.show()

"""## Decision Tree - Information Gain"""

from sklearn.tree import DecisionTreeClassifier

dt_classifier = DecisionTreeClassifier(criterion='entropy')

dt_classifier.fit(x_resample, y_resample)

y_pred_dt = dt_classifier.predict(X_test_scaled)

y_pred_dt

y_pred_prob_dt = dt_classifier.predict_proba(X_test_scaled)
y_pred_prob_dt = pd.DataFrame(y_pred_prob_dt)
y_pred_prob_dt

print('Accuracy of Decision Tree(Information Gain) on Training data : ', dt_classifier.score(x_resample, y_resample))

print('Accuracy of Decision Tree(Information Gain) on Test data: ', dt_classifier.score(X_test_scaled, y_test))

confusion_matrix(y_test, y_pred_dt)

print(classification_report(y_test, y_pred_dt))

y_pred_proba = y_pred_prob_dt.iloc[:,1]
fpr, tpr, _ = metrics.roc_curve(y_test,  y_pred_proba)
auc_dt_ig = metrics.auc(fpr, tpr)
print('AUC: ',auc_dt_ig)

plt.plot(fpr,tpr)
plt.ylabel('True Positive Rate')
plt.xlabel('False Positive Rate')
plt.title('ROC Curve for Decision Tree(Information Gain)')
plt.show()

"""## Decision Tree- Gini Index"""

gini_classifier = DecisionTreeClassifier(criterion='gini', random_state = 0)

gini_classifier.fit(x_resample, y_resample)

y_pred_gini= gini_classifier.predict(X_test_scaled)

y_pred_prob_gini = gini_classifier.predict_proba(X_test_scaled)
y_pred_prob_gini=pd.DataFrame(y_pred_prob_gini)
y_pred_prob_gini

print('Accuracy of Decision Tree(Gini Index) on Training data : ')
gini_classifier.score(x_resample, y_resample)

print('Accuracy of Decision Tree(Gini Index) on Test data: ')
gini_classifier.score(X_test_scaled, y_test)

confusion_matrix(y_test, y_pred_gini)

print(classification_report(y_test, y_pred_gini))

y_pred_proba = y_pred_prob_gini.iloc[:,1]
fpr, tpr, _ = metrics.roc_curve(y_test,  y_pred_proba)
auc_dt_gini = metrics.auc(fpr, tpr)
print('AUC: ', auc_dt_gini)

plt.plot(fpr,tpr)
plt.ylabel('True Positive Rate')
plt.xlabel('False Positive Rate')
plt.title('ROC Curve for Decision Tree(Gini)')
plt.show()

"""## Random Forest"""

from sklearn.ensemble import RandomForestClassifier
rf_classifier = RandomForestClassifier(n_estimators= 100, criterion="entropy")
rf_classifier.fit(x_resample, y_resample)

y_pred_rf= rf_classifier.predict(X_test_scaled)

y_pred_rf

y_pred_prob_rf = rf_classifier.predict_proba(X_test_scaled)
y_pred_prob_rf=pd.DataFrame(y_pred_prob_rf)
y_pred_prob_rf

print('Accuracy of Random Forest on Training data : ', rf_classifier.score(x_resample, y_resample)*100)

print('Accuracy of Random Forest on Test data: ', rf_classifier.score(X_test_scaled, y_test)*100)

confusion_matrix(y_test, y_pred_rf)

print(classification_report(y_test, y_pred_rf))

y_pred_proba = y_pred_prob_rf.iloc[:,1]
fpr, tpr, _ = metrics.roc_curve(y_test,  y_pred_proba)
auc_rf = metrics.auc(fpr, tpr)
print('AUC: ',auc_rf)

plt.plot(fpr,tpr)
plt.ylabel('True Positive Rate')
plt.xlabel('False Positive Rate')
plt.title('ROC Curve for Random Forest')
plt.show()

"""## Determining the best model for our Dataset - Visualisation"""

from sklearn.metrics import precision_score, accuracy_score, f1_score, recall_score

#PRECISION

precision_score_list = [precision_score(y_test, y_pred), precision_score(y_test, y_pred_knn), precision_score(y_test, y_pred_dt), precision_score(y_test, y_pred_gini), precision_score(y_test, y_pred_rf)]
model_name_list = ['LogisticRegression', 'KNN', 'DecisionTree(Info Gain)', 'DecisionTree(Gini Index)' ,'RandomForest']

sns.barplot(x = model_name_list, y = precision_score_list, palette = 'mako')
plt.xlabel('Model')
plt.ylabel('Precision Score')
plt.title('Precision Scores of Different Models')
plt.ylim(0,1)
plt.xticks(rotation = 45)
plt.grid(axis = 'y')
plt.show()

print('Best Model according to Precision : ', model_name_list[precision_score_list.index(max(precision_score_list))],'\nWith Precison Value: ',max(precision_score_list))

#RECALL SCORE

recall_score_list = [recall_score(y_test, y_pred), recall_score(y_test, y_pred_knn), recall_score(y_test, y_pred_dt), recall_score(y_test, y_pred_gini), recall_score(y_test, y_pred_rf)]
model_name_list = ['LogisticRegression', 'KNN', 'DecisionTree(Info Gain)', 'DecisionTree(Gini Index)', 'RandomForest']

sns.barplot(x = model_name_list, y = recall_score_list, palette = 'BuGn_d')
plt.xlabel('Model')
plt.ylabel('Recall Score')
plt.title('Recall Scores of Different Models')
plt.ylim(0, 1)
plt.xticks(rotation = 45)
plt.grid(axis = 'y')
plt.show()

print('Best Model According to Recall Score: ', model_name_list[recall_score_list.index(max(recall_score_list))], '\nWith Recall Value: ', max(recall_score_list))

#F1 SCORE

f1_score_list = [f1_score(y_test, y_pred), f1_score(y_test, y_pred_knn), f1_score(y_test, y_pred_dt), f1_score(y_test, y_pred_gini), f1_score(y_test, y_pred_rf)]
model_name_list = ['LogisticRegression', 'KNN', 'DecisionTree(Info Gain)', 'DecisionTree(Gini Index)', 'RandomForest']

sns.barplot(x = model_name_list, y = f1_score_list, palette = 'BuPu')
plt.xlabel('Model')
plt.ylabel('F1 Score')
plt.title('F1 Scores of Different Models')
plt.ylim(0,1)
plt.xticks(rotation = 45)
plt.grid(axis = 'y')
plt.show()

print('Best Model According to F1 Score: ', model_name_list[f1_score_list.index(max(f1_score_list))], '\nWith F1 Score: ', max(f1_score_list))

#ACCURACY

accuracy_score_list = [accuracy_score(y_test, y_pred), accuracy_score(y_test, y_pred_knn), accuracy_score(y_test, y_pred_dt), accuracy_score(y_test, y_pred_gini), accuracy_score(y_test, y_pred_rf)]
model_name_list = ['LogisticRegression', 'KNN', 'DecisionTree(Info Gain)', 'DecisionTree(Gini Index)', 'RandomForest']

sns.barplot(x = model_name_list, y = accuracy_score_list,palette = 'flare')
plt.xlabel('Model')
plt.ylabel('Accuracy Score')
plt.title('Accuracy Scores of Different Models')
plt.ylim(0,1)
plt.xticks(rotation = 45)
plt.grid(axis = 'y')
plt.show()

print('Best Model According to Accuracy Score: ', model_name_list[accuracy_score_list.index(max(accuracy_score_list))], '\nWith an Accuracy: ', max(accuracy_score_list)*100, '%')

#AUC - Area Under the Curve

auc_list = [auc_log, auc_knn, auc_dt_ig, auc_dt_gini, auc_rf]
model_name_list = ['LogisticRegression', 'KNN', 'DecisionTree(Info Gain)', 'DecisionTree(Gini Index)', 'RandomForest']

sns.barplot(x = model_name_list, y = auc_list, palette = 'GnBu_d')
plt.xlabel('Model')
plt.ylabel('AUC')
plt.title('AUC of Different Models')
plt.ylim(0,1)
plt.xticks(rotation = 45)
plt.grid(axis = 'y')
plt.show()

print('Best Model According to AUC: ', model_name_list[auc_list.index(max(auc_list))], '\nWith AUC: ',max(auc_list))

#Overall, Random Forest performed the best for all metrics except recall, for recall KNN performed the best.
#In this case, with an Accuracy of 96.65116279069767 % Random Forest proved to be the best model.

